<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Extracting surface data in VertexWiseR • VertexWiseR</title>
<script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Extracting surface data in VertexWiseR">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">VertexWiseR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.2.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Functions</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/Python_troubleshooting.html">Python troubleshooting</a></li>
    <li><a class="dropdown-item" href="../articles/VertexWiseR_Example_1.html">Example analyses with VertexWiseR - Example 1</a></li>
    <li><a class="dropdown-item" href="../articles/VertexWiseR_Example_2.html">Example analyses with VertexWiseR - Example 2</a></li>
    <li><a class="dropdown-item" href="../articles/VertexWiseR_surface_extraction.html">Extracting surface data in VertexWiseR</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Updates</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch">
<li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul>
</li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Extracting surface data in VertexWiseR</h1>
                        <h4 data-toc-skip class="author">Charly Billaud,
Junhong Yu</h4>
            
            <h4 data-toc-skip class="date">2024-12-12</h4>
      

      <div class="d-none name"><code>VertexWiseR_surface_extraction.Rmd</code></div>
    </div>

    
    
<p>As of version 1.2.0, four functions in VertexWiseR do surface data
extraction and synthesis: SURFvextract(), FSLRvextract(),
CAT12vextract() and HIPvextract().</p>
<p>Surface extraction consists in reading through a preprocessing
pipeline’s subjects directory, collating the surface data (for a chosen
vertex-wise measures, e.g. thickness), and summarising it into one
compact matrix R object, with N rows per subject and M columns per
vertex values.</p>
<div class="figure" style="text-align: center">
<img src="surfextract.jpg" alt="Surface extraction methods workflow" width="100%"><p class="caption">
Surface extraction methods workflow
</p>
</div>
<p>The functions save such objects as a .rds file. The file contains the
R surface matrix and, with the default subj_ID setting, an appended list
of the corresponding subjects ID. This file can be shared across any
device with R and all VertexWiseR statistical analyses functions can be
run on these, without the need to access the initially preprocessed
data.</p>
<div class="section level2">
<h2 id="extracting-cortical-surface-data-from-freesurfer">Extracting cortical surface data: from FreeSurfer<a class="anchor" aria-label="anchor" href="#extracting-cortical-surface-data-from-freesurfer"></a>
</h2>
<p>SURFvextract() extracts cortical surface data from a preprocessed
FreeSurfer subjects directory <span class="citation">(Fischl
2012)</span>.</p>
<p>The function makes use of internal FreeSurfer functions to resample
every participant’s individual surface to fsaverage5 or fsaverage6.
Therefore, it requires FreeSurfer to be installed and set in the
environment where R is run and cannot be automatically run here.</p>
<p>For demonstration, we provide a subsample of 2 participants from the
<a href="https://openneuro.org/datasets/ds003592/versions/1.0.13" class="external-link">SPRENG
dataset</a> <span class="citation">(Spreng et al. 2022)</span>, after
preprocessing their surface data using FreeSurfer’s default recon-all
pipeline. Certain files that were not needed (volumes, surfaces, label
files) were removed to minimise the subsample’s size.</p>
<p>The subsample (29.6 MB) can be downloaded from the repository as
follows (unzip can be changed to untar if errors occur):</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># download and unzip the surface data directory</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/download.file.html" class="external-link">download.file</a></span><span class="op">(</span>url <span class="op">=</span> <span class="st">"https://github.com/CogBrainHealthLab/VertexWiseR/blob/main/inst/demo_data/spreng_surf_data_freesurfer.zip?raw=TRUE"</span>, </span>
<span>              destfile <span class="op">=</span> <span class="st">"spreng_surf_data_freesurfer.zip"</span>,</span>
<span>              mode<span class="op">=</span><span class="st">'wb'</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/unzip.html" class="external-link">unzip</a></span><span class="op">(</span><span class="st">"spreng_surf_data_freesurfer.zip"</span><span class="op">)</span></span></code></pre></div>
<p>We give the following code as example:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">SPRENG_CTv</span> <span class="op">=</span> <span class="fu"><a href="../reference/SURFvextract.html">SURFvextract</a></span><span class="op">(</span>sdirpath <span class="op">=</span> <span class="st">'spreng_surf_data_freesurfer'</span>, </span>
<span>             filename <span class="op">=</span> <span class="st">"SPRENG_CTv.rds"</span>, </span>
<span>             template<span class="op">=</span><span class="st">'fsaverage5'</span>, </span>
<span>             measure <span class="op">=</span> <span class="st">'thickness'</span>,</span>
<span>             subj_ID <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<ul>
<li>The following arguments can be used:
<ul>
<li>sdirpath: Path to the preprocessed subjects directory (will be used
to define the SUBJECTS_DIR variable automatically)</li>
<li>filename: Name of the saved .rds output (can include a specific path
to it)</li>
<li>template: The surface template space in which to extract the data,
which can be ‘fsaverage5’ (default) or ‘fsaverage6’</li>
<li>measure: The name of the surface-based measure of interest computed
<a href="https://surfer.nmr.mgh.harvard.edu/fswiki/UserContributions/FAQ" class="external-link">in
FreeSurfer</a>. That includes cortical thickness (‘thickness’), surface
curvature (‘curv’), depth/height of vertex (‘sulc’), surface area
(‘area’), and ‘volume’ (for freesurfer 7.4.1 or later). Default is
‘thickness’.</li>
<li>subj_ID Whether to obtain a list object containing both subject ID
and data matrix instead of just the matrix (TRUE OR FALSE)</li>
</ul>
</li>
</ul>
<p>An example of surface matrix object, extracted from FreeSurfer
preprocessing of the all site 1 participants is available on VertexWiseR
online repository:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">SPRENG_CTv</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/readRDS.html" class="external-link">readRDS</a></span><span class="op">(</span>file <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/connections.html" class="external-link">url</a></span><span class="op">(</span><span class="st">"https://github.com/CogBrainHealthLab/VertexWiseR/blob/main/inst/demo_data/SPRENG_CTv_site1.rds?raw=TRUE"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">SPRENG_CTv</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1]   238 20484</span></span></code></pre>
<p>What dim(SPRENG_CTv) shows is that the matrix object contains the
surface values of 238 participants, each with 20484 thickness values
which correspond to the vertices of fsaverage5, both left-to-right
hemispheres.</p>
<p>When the subj_ID argument is set to TRUE, the object returned is not
a matrix on its own but a list containing both the matrix and an array
listing the subject IDs from the directory. In our example: *
SPRENG_CTv[[1]] will be the list of subject IDs * SPRENG_CTv[[2]] will
be the matrix object</p>
</div>
<div class="section level2">
<h2 id="extracting-cortical-surface-data-from-hcp-and-fmriprep">Extracting cortical surface data: from HCP and fMRIprep<a class="anchor" aria-label="anchor" href="#extracting-cortical-surface-data-from-hcp-and-fmriprep"></a>
</h2>
<p>FSLRvextract() extracts cortical data in FSLR32k surface space from
Human Connectome Project (HCP) <span class="citation">(Van Essen et al.
2013)</span> or fMRIprep <span class="citation">(Esteban et al.
2019)</span> preprocessing output directories. FSLRvextract() requires
the <a href="https://humanconnectome.org/software/get-connectome-workbench" class="external-link">HCP
workbench</a> to be installed, and uses the ciftiTools R package to read
the .dscalar.nii files.</p>
<p>For demonstration, we provide a subsample of 2 participants from the
<a href="https://openneuro.org/datasets/ds003592/versions/1.0.13" class="external-link">SPRENG
dataset</a> <span class="citation">(Spreng et al. 2022)</span>, after
preprocessing their surface data using fMRIprep. The latter outputs
fslr32k surface data when using the “–cifti-output” option <span class="citation">(Esteban et al. 2019)</span>. Other anatomical files
were removed and only the dscalar.nii and associated json files were
preserved, to minimise its size.</p>
<p>The subsample (14.1 MB) can be downloaded from the repository as
follows (unzip can be changed to untar if errors occur):</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># download and unzip the surface data directory</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/download.file.html" class="external-link">download.file</a></span><span class="op">(</span>url <span class="op">=</span> <span class="st">"https://github.com/CogBrainHealthLab/VertexWiseR/blob/main/inst/demo_data/spreng_surf_data_fmriprep.zip?raw=TRUE"</span>, </span>
<span>              destfile <span class="op">=</span> <span class="st">"spreng_surf_data_fmriprep.zip"</span>,</span>
<span>              mode<span class="op">=</span><span class="st">'wb'</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/unzip.html" class="external-link">unzip</a></span><span class="op">(</span><span class="st">"spreng_surf_data_fmriprep.zip"</span><span class="op">)</span></span></code></pre></div>
<p>FSLRvextract() gets the data from .dscalar.nii files associated with
the specified measure (e.g. thickness, curv), and can extract it as
follows (specify your own connectome workbench path):</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat_fslr32k</span><span class="op">=</span><span class="fu"><a href="../reference/FSLRvextract.html">FSLRvextract</a></span><span class="op">(</span>sdirpath<span class="op">=</span><span class="st">"spreng_surf_data/"</span>,</span>
<span>            wb_path<span class="op">=</span><span class="st">"path/to/workbench"</span>,</span>
<span>            filename<span class="op">=</span><span class="st">"dat_fslr32k.rds"</span>,</span>
<span>            dscaler<span class="op">=</span><span class="st">"_space-fsLR_den-91k_thickness.dscalar.nii"</span>,</span>
<span>            subj_ID <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>            silent<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<ul>
<li>The following arguments can be used:
<ul>
<li>sdirpath: Path to the preprocessed subjects directory</li>
<li>wb_path: Path to the HCP workbench directory</li>
<li>filename: Name of the saved .rds output (can include a specific path
to it)</li>
<li>dscaler: Suffix of the dscaler surface files. Because these files
are named differently depending on the preprocessing pipeline, the user
needs to specify what they are in the dataset.</li>
<li>subj_ID Whether to obtain a list object containing both subject ID
and data matrix instead of just the matrix (TRUE OR FALSE). Default is
TRUE.</li>
<li>silent: Whether to silence messages from the process (TRUE or
FALSE). Default is FALSE.</li>
</ul>
</li>
</ul>
<p>Accordingly, the dat_fslr32k matrix will contain 2 rows (for 2
participants) and 64,984 columns (the subject’s cortical thickness
values in every vertex of the fslr32k surface).</p>
</div>
<div class="section level2">
<h2 id="extracting-cortical-surface-data-from-cat12">Extracting cortical surface data: from CAT12<a class="anchor" aria-label="anchor" href="#extracting-cortical-surface-data-from-cat12"></a>
</h2>
<p>CAT12vextract() was implemented in version 1.2.0 and can extract
surface preprocessed with the CAT12 <span class="citation">(Gaser et al.
2024)</span> surface based morphometry pipeline. The function requires
reticulate <span class="citation">(Ushey, Allaire, and Tang 2023)</span>
to run.</p>
<p>For demonstration, we provide again a subsample of 2 participants
from the <a href="https://openneuro.org/datasets/ds003592/versions/1.0.13" class="external-link">SPRENG
dataset</a> <span class="citation">(Spreng et al. 2022)</span>, after
preprocessing their surface data using CAT12’s SBM pipeline
(segmentation and resampling without smoothing), and extracting
different possible surface measures. Only the 32k mesh .gii and .dat
files were kept.</p>
<p>The subsample (~13 MB) can be downloaded from the repository as
follows (unzip can be changed to untar if errors occur):</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># download and unzip the surface data directory</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/download.file.html" class="external-link">download.file</a></span><span class="op">(</span>url <span class="op">=</span> <span class="st">"https://github.com/CogBrainHealthLab/VertexWiseR/blob/main/inst/demo_data/spreng_surf_data_cat12.zip?raw=TRUE"</span>, </span>
<span>              destfile <span class="op">=</span> <span class="st">"spreng_surf_data_cat12.zip"</span>,</span>
<span>              mode<span class="op">=</span><span class="st">'wb'</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/unzip.html" class="external-link">unzip</a></span><span class="op">(</span><span class="st">"spreng_surf_data_cat12.zip"</span><span class="op">)</span></span></code></pre></div>
<p>CAT12vextract() extracts surface data resampled to 32k meshes (with
or without smoothing) and can be used as in this example:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">CATsurf</span><span class="op">=</span><span class="fu"><a href="../reference/CAT12vextract.html">CAT12vextract</a></span><span class="op">(</span>sdirpath<span class="op">=</span><span class="st">"SPRENG_CAT12_subsample"</span>, </span>
<span>                      filename<span class="op">=</span><span class="st">'thickness.rds'</span>, </span>
<span>                      measure<span class="op">=</span><span class="st">'thickness'</span>, </span>
<span>                      subj_ID <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                      silent <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<ul>
<li>The following arguments can be used:
<ul>
<li>sdirpath: Path to the preprocessed subjects directory (will be used
to define the SUBJECTS_DIR variable automatically). We recommend that
the directory follows the <a href="https://bids.neuroimaging.io/" class="external-link">BIDS</a> structure for
accuracy.</li>
<li>filename: Name of the saved .rds output (can include a specific path
to it)</li>
<li>measure: The name of the surface-based measure of interest computed
<a href="https://neuro-jena.github.io/cat12-help/#sbm" class="external-link">in CAT12</a>.
That includes ‘thickness’, ‘depth’, ‘fractaldimension’, ‘gyrification’,
and ‘toroGI20mm’.</li>
<li>subj_ID Whether to obtain a list object containing both subject ID
and data matrix instead of just the matrix (TRUE OR FALSE)</li>
</ul>
</li>
</ul>
<p>Accordingly, the matrix will contained 2 rows (for 2 participants)
and 64,984 columns (the subject’s cortical thickness values in every
vertex of the 32k mesh):</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#The surface object contains the surface matrix and the list of subjects ID (and session number if applicable)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">CATsurf</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] "sub_list" "surf_obj"</span></span></code></pre>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#The surface matrix dimensions:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">CATsurf</span><span class="op">$</span><span class="va">surf_obj</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1]     2 64984</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="extracting-hippocampal-surface-data-from-hippunfold">Extracting hippocampal surface data: from HippUnfold<a class="anchor" aria-label="anchor" href="#extracting-hippocampal-surface-data-from-hippunfold"></a>
</h2>
<p>HIPvextract() extracts cortical data in CITI168 surface space from
the HippUnfold preprocessing pipeline <span class="citation">(DeKraker
et al. 2023)</span>. As opposed to the other two functions,
HIPvextract() does not require any system requirement.</p>
<p>For demonstration, we provide a subsample of 2 participants from the
<a href="https://openneuro.org/datasets/ds003799/versions/2.0.0" class="external-link">Fink
dataset</a> <span class="citation">(Fink et al. 2021)</span>, after
preprocessing their surface data using HippUnfold, keeping all output
.gii files. The subsample (11.3 MB) can be downloaded from the
repository as follows (untar can be changed to unzip if errors
occur):</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># download and unzip the surface data directory</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/download.file.html" class="external-link">download.file</a></span><span class="op">(</span>url <span class="op">=</span> <span class="st">"https://github.com/CogBrainHealthLab/VertexWiseR/blob/main/inst/demo_data/fink_surf_data_hippunfold.zip?raw=TRUE"</span>, </span>
<span>              destfile <span class="op">=</span> <span class="st">"fink_surf_data_hippunfold.zip"</span>, </span>
<span>              mode <span class="op">=</span> <span class="st">"wb"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/untar.html" class="external-link">untar</a></span><span class="op">(</span><span class="st">"fink_surf_data_hippunfold.zip"</span><span class="op">)</span></span></code></pre></div>
<p>To extract and collate the data of the two participants,
HIPvextract() can be run as follows:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hipp_surf</span><span class="op">=</span><span class="fu"><a href="../reference/HIPvextract.html">HIPvextract</a></span><span class="op">(</span>sdirpath<span class="op">=</span><span class="st">"fink_surf_data"</span>,</span>
<span>            filename<span class="op">=</span><span class="st">"hippocampal_surf.rds"</span>,</span>
<span>            measure<span class="op">=</span><span class="st">"thickness"</span>,</span>
<span>            subj_ID <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> </span></code></pre></div>
<ul>
<li>The following arguments can be used:
<ul>
<li>sdirpath: Path to the preprocessed subjects directory</li>
<li>filename: Name of the saved .rds output (can include a specific path
to it)</li>
<li>measure: The name of the surface-based measure of interest computed
<a href="https://hippunfold.readthedocs.io/en/latest/outputs/output_files.html#surface-metrics" class="external-link">in
HippUnfold</a>. That includes ‘thickness’,‘curvature’,‘gyrification’ and
‘surfarea’. Default is ‘thickness’</li>
<li>subj_ID: Whether to obtain a list object containing both subject ID
and data matrix instead of just the matrix (TRUE OR FALSE). Default is
TRUE.</li>
</ul>
</li>
</ul>
<p>Note that when subjects directories have multiple sessions, the
matrix object will contain N rows per participant and per session.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hipp_surf</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] "sub-season101_ses-1" "sub-season101_ses-2" "sub-season101_ses-3"</span></span>
<span><span class="co">## [4] "sub-season102_ses-1" "sub-season102_ses-2" "sub-season102_ses-3"</span></span></code></pre>
<p>Here the matrix has 6 rows for 2 particiants with 3 sessions each;
and 14,524 columns (the hippocampal thickness values in every vertex of
the CITI168 surface).</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">hipp_surf</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1]     6 14524</span></span></code></pre>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References:<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-dekraker_evaluation_2023" class="csl-entry">
DeKraker, Jordan, Nicola Palomero-Gallagher, Olga Kedo, Neda
Ladbon-Bernasconi, Sascha EA Muenzing, Markus Axer, Katrin Amunts, Ali R
Khan, Boris C Bernhardt, and Alan C Evans. 2023. <span>“Evaluation of
Surface-Based Hippocampal Registration Using Ground-Truth Subfield
Definitions.”</span> Edited by Anna C Schapiro and Laura L Colgin.
<em>eLife</em> 12 (November): RP88404. <a href="https://doi.org/10.7554/eLife.88404" class="external-link">https://doi.org/10.7554/eLife.88404</a>.
</div>
<div id="ref-esteban_fmriprep_2019" class="csl-entry">
Esteban, Oscar, Christopher J. Markiewicz, Ross W. Blair, Craig A.
Moodie, A. Ilkay Isik, Asier Erramuzpe, James D. Kent, et al. 2019.
<span>“<span class="nocase">fMRIPrep</span>: A Robust Preprocessing
Pipeline for Functional <span>MRI</span>.”</span> <em>Nature
Methods</em> 16 (1): 111–16. <a href="https://doi.org/10.1038/s41592-018-0235-4" class="external-link">https://doi.org/10.1038/s41592-018-0235-4</a>.
</div>
<div id="ref-fink_two-week_2021" class="csl-entry">
Fink, Andreas, Karl Koschutnig, Thomas Zussner, Corinna M.
Perchtold-Stefan, Christian Rominger, Mathias Benedek, and Ilona
Papousek. 2021. <span>“A Two-Week Running Intervention Reduces Symptoms
Related to Depression and Increases Hippocampal Volume in Young
Adults.”</span> <em>Cortex</em> 144 (November): 70–81. <a href="https://doi.org/10.1016/j.cortex.2021.08.010" class="external-link">https://doi.org/10.1016/j.cortex.2021.08.010</a>.
</div>
<div id="ref-fischl_freesurfer_2012" class="csl-entry">
Fischl, Bruce. 2012. <span>“<span>FreeSurfer</span>.”</span>
<em>NeuroImage</em> 62 (2): 774–81. <a href="https://doi.org/10.1016/j.neuroimage.2012.01.021" class="external-link">https://doi.org/10.1016/j.neuroimage.2012.01.021</a>.
</div>
<div id="ref-gaser_cat_2024" class="csl-entry">
Gaser, Christian, Robert Dahnke, Paul M Thompson, Florian Kurth, Eileen
Luders, and the Alzheimer’s Disease Neuroimaging Initiative. 2024.
<span>“<span>CAT</span>: A Computational Anatomy Toolbox for the
Analysis of Structural <span>MRI</span> Data.”</span>
<em>GigaScience</em> 13 (January): giae049. <a href="https://doi.org/10.1093/gigascience/giae049" class="external-link">https://doi.org/10.1093/gigascience/giae049</a>.
</div>
<div id="ref-spreng_neurocognitive_2022" class="csl-entry">
Spreng, R. Nathan, Roni Setton, Udi Alter, Benjamin N. Cassidy, Bri
Darboh, Elizabeth DuPre, Karin Kantarovich, et al. 2022.
<span>“Neurocognitive Aging Data Release with Behavioral, Structural and
Multi-Echo Functional <span>MRI</span> Measures.”</span> <em>Scientific
Data</em> 9 (1): 119. <a href="https://doi.org/10.1038/s41597-022-01231-7" class="external-link">https://doi.org/10.1038/s41597-022-01231-7</a>.
</div>
<div id="ref-ushey_reticulate_2023" class="csl-entry">
Ushey, K, J Allaire, and Y Tang. 2023. <span>“Reticulate:
<span>Interface</span> to ’<span>Python</span>’.”</span> <a href="https://CRAN.R-project.org/package=reticulate" class="external-link">https://CRAN.R-project.org/package=reticulate</a>.
</div>
<div id="ref-van_essen_wu-minn_2013" class="csl-entry">
Van Essen, David C., Stephen M. Smith, Deanna M. Barch, Timothy E. J.
Behrens, Essa Yacoub, and Kamil Ugurbil. 2013. <span>“The
<span>WU</span>-<span>Minn</span> <span>Human</span>
<span>Connectome</span> <span>Project</span>: <span>An</span>
<span>Overview</span>.”</span> <em>NeuroImage</em> 80 (October): 62–79.
<a href="https://doi.org/10.1016/j.neuroimage.2013.05.041" class="external-link">https://doi.org/10.1016/j.neuroimage.2013.05.041</a>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Junhong Yu, Charly Billaud.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.9000.</p>
</div>

    </footer>
</div>





  </body>
</html>
